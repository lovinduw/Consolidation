{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Internal Inconsistencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import glob\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from IPython.display import display\r\n",
    "import import_ipynb\r\n",
    "import data_preperation as dp\r\n",
    "import copy\r\n",
    "import pyomo.environ as pyo\r\n",
    "from pyomo.opt import SolverFactory\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from data_preperation.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "countries={ 'Austria': 'AT', 'Belgium': 'BE',  'Bulgaria': 'BG', 'Switzerland': 'CH', 'Czech Republic': 'CZ', 'Germany': 'DE', 'Denmark': 'DK', 'Estonia': 'EE', 'Spain': 'ES', 'Finland': 'FI', 'France': 'FR',  'Greece': 'GR', 'Hungary': 'HU', 'Ireland': 'IE', 'Italy': 'IT', 'Lithuania': 'LT', 'Latvia': 'LV', 'Montenegro': 'ME','Netherlands': 'NL', 'Norway': 'NO', 'Poland': 'PL', 'Portugal': 'PT', 'Serbia': 'RS', 'Sweden': 'SE', 'Slovenia': 'SI', 'Slovakia': 'SK', 'United Kingdom': 'UK'}\r\n",
    "\r\n",
    "abbr_list=list(countries.values())\r\n",
    "\r\n",
    "# load_data = dp.load(countries)\r\n",
    "# generation_data = dp.generation(countries)\r\n",
    "# cross_border_data = dp.cross_border(abbr_list)[1]\r\n",
    "# import_export_using_crossborder_data = dp.import_export_using_crossborder(dp.cross_border(abbr_list)[0],abbr_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Internal inconsistencies based on unedited ENTSO-E data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Calculating missing values and mismatch analysis in data files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def omit_dst(df):\r\n",
    "\r\n",
    "    # Due to day light saving, all the datasets have null values on 25th March from 02:00 - 03:00. \r\n",
    "    # Considering the time intervals each country update the data, a total number of rows of 4,2 or 1 are dropped from the 31st March, 02:00 - 03:00 time interval.\r\n",
    "    # Also this returns a integer ('divider') based on the file length to get the energy values in a later step. In 15 min interval files this is 4, in 30 min interval files this is 2 and in 1 hour interval files this is 1.\r\n",
    "    \r\n",
    "    length = len(df)\r\n",
    "    if length == 35044:\r\n",
    "        df = df.drop(range(7976, 7980)).reset_index(drop=True)\r\n",
    "        divider = 4\r\n",
    "    elif length == 17522:\r\n",
    "        df = df.drop(range(3988, 3990)).reset_index(drop=True)\r\n",
    "        divider = 2\r\n",
    "    else:\r\n",
    "        df = df.drop(range(1994, 1995)).reset_index(drop=True)\r\n",
    "        divider = 1\r\n",
    "    \r\n",
    "    return(df,divider)\r\n",
    "\r\n",
    "def mismatch_raw_data(countries):\r\n",
    "\r\n",
    "    load_missing_data = []\r\n",
    "    generation_missing_data = []\r\n",
    "    transmission_missing_data =[]\r\n",
    "    transmission_files = []\r\n",
    "    temp1 = pd.DataFrame()\r\n",
    "    temp2 = pd.DataFrame()\r\n",
    "    \r\n",
    "    mismatch_data = {}\r\n",
    "    csvs = glob.glob(\"../Data Sources/ENTSO-E/2018/Transmission/*.csv\")\r\n",
    "\r\n",
    "    # In the following command we read each csv file and drop the rows related to day light saving using 'omit_dst' function\r\n",
    "    # Then we save the total number of null values in load data of each country in the load_missing_data list.\r\n",
    "    # Then we save the total number of null values in generation data of each country in the generation_missing_data list.\r\n",
    "    # Then we get the list of the paths of all files in the directory to the 'csvs' variable using 'glob' function.\r\n",
    "    # Then one by one the actual csv associated with the path is copied to the dataframe 'temp' only if the file path string includes the country_code sent by 'abbr'. \r\n",
    "    # Then we save the total number of null values in each transmission datafile of each country in the transmission_missing_data list.\r\n",
    "    # Then we update all the generation & load missing values in the 'temp1' dataframe and transmission missing values in 'temp2' dataframe.\r\n",
    "    \r\n",
    "    # We calculate the annual data mismatch of each country as (generation + imports - load - exports) of the country.\r\n",
    "    # Countries provide the data in 15 min, 30 min and 1 hour intervals.\r\n",
    "    # Therefore to ge the energy values from the power values, we divide the total power data by 4,2 or 1 using the 'divider' variable as required.\r\n",
    "    \r\n",
    "    for country,abbr in countries.items():\r\n",
    "        load_data,divider_load = omit_dst(pd.read_csv(f'../Data Sources/ENTSO-E/2018/Load/{country}.csv'))\r\n",
    "        generation_data, divider_gen = omit_dst(pd.read_csv(f'../Data Sources/ENTSO-E/2018/Generation/{country}.csv', low_memory=False))\r\n",
    "        \r\n",
    "        load_missing_data.append(load_data.isnull().sum().sum())\r\n",
    "        generation_missing_data.append(generation_data.isnull().sum().sum())\r\n",
    "        \r\n",
    "        transmission_data = pd.DataFrame()\r\n",
    "        transmission_data_temp = pd.DataFrame()\r\n",
    "\r\n",
    "        for csv in csvs:\r\n",
    "            if csv[42:44] == abbr:\r\n",
    "                temp, divider_transmission = omit_dst(pd.read_csv(csv))\r\n",
    "                transmission_missing_data.append(temp.isnull().sum().sum())\r\n",
    "                transmission_files.append(f'{csv[42:44]} --> {csv[45:47]}')\r\n",
    "                \r\n",
    "                temp = temp.replace(['n/e',np.nan] ,0)\r\n",
    "                transmission_data_temp[f'{csv[42:44]} -- > {csv[45:47]}'] = pd.to_numeric(temp.iloc[:,2])\r\n",
    "                transmission_data_temp[f'{csv[42:44]} < -- {csv[45:47]}'] = pd.to_numeric(temp.iloc[:,1])  \r\n",
    "            \r\n",
    "        transmission_data = pd.concat([transmission_data,transmission_data_temp/divider_transmission],axis=1)\r\n",
    "        mismatch_data.update({f'{abbr}': round(abs(generation_data.iloc[:, 2:].sum(axis=1).sum()/divider_gen + transmission_data.filter(like=f'{abbr} <').sum(\r\n",
    "            axis=1).sum() - load_data.iloc[:, 2].sum()/divider_load - transmission_data.filter(like=f'{abbr} -').sum(axis=1).sum())/1000000,2)})\r\n",
    "\r\n",
    "    temp1['File'] = list(countries.values())\r\n",
    "    temp2['File'] = transmission_files\r\n",
    "    temp1['No. of missing data in Load data'] = load_missing_data\r\n",
    "    temp1['No. of missing data in Generation data'] = generation_missing_data\r\n",
    "    temp2['No. of missing data in Transmission data'] = transmission_missing_data\r\n",
    "    \r\n",
    "    mismatch_data = sorted(mismatch_data.items(), key= lambda item: item[1], reverse=True)\r\n",
    "    \r\n",
    "    display(temp1, temp2)   \r\n",
    "\r\n",
    "    width = 0.35\r\n",
    "    labels = [x[0] for x in mismatch_data]\r\n",
    "    X = np.arange(len(labels))\r\n",
    "    plt.figure(figsize=(20,10))\r\n",
    "    plt.bar([x for x in X], [x[1] for x in mismatch_data], width, color='aqua',edgecolor='black')\r\n",
    "    plt.xlabel('Countries')\r\n",
    "    plt.ylabel('Mismatch [TWh]')\r\n",
    "    plt.title('Mismatch analysis based on (generation + imports - load - exports) in raw ENTSO-E data')\r\n",
    "    plt.grid()\r\n",
    "    plt.xticks(X,labels)\r\n",
    "    plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Internal inconsistencies based on gap filled ENTSO-E data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Internal Sigma Approach"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def internal_sigma(load_dic, generation_dic, transmission_data, countries):\r\n",
    "\r\n",
    "    abbr_list = list(countries.values())\r\n",
    "    load_dic_copy = copy.deepcopy(load_dic)\r\n",
    "    generation_dic_copy = copy.deepcopy(generation_dic)\r\n",
    "    transmission_data_copy = copy.deepcopy(transmission_data)\r\n",
    "\r\n",
    "    # In the following command, we calculate the sigma value by sending it to 'data_preperation.ipynb'\r\n",
    "\r\n",
    "    sigma = dp.sigma(load_dic_copy, generation_dic_copy, transmission_data_copy, abbr_list)\r\n",
    "    print('SIGMA CALCULATED')\r\n",
    "\r\n",
    "    # In the follwoing commands we create a 'country_index' with the names abbreviations of the 27 countries we consider.\r\n",
    "    # Then we create a 'time_index' which is a list of integers from 0 to 8760 which indicates the timesteps \r\n",
    "    # Then we create a 'generation_index' which is a dictionary with country_abbreviations as keys and generation_sources os each country as the values of each key.\r\n",
    "    # Then we create a 'generation_fuels' which is a list of all the generation_sources we consider.\r\n",
    "    # Then we create 2 dictionaries 'imports_index' and 'exports_index' with country_abbreviations as the keys.\r\n",
    "    # In the column heads of 'transmission_data' dataframe, if the name of the key is in the first two characters of the column head, that column head goes as the value in 'export_index' dictionary\r\n",
    "    # In the column heads of 'transmission_data' dataframe, if the name of the key is in the last two characters of the column head, that column head goes as the value in 'import_index' dictionary\r\n",
    "    # Then we create a 'transmission_index' with all the column heads of 'transmission_data' dataframe.\r\n",
    "\r\n",
    "    country_index = list(countries.values())\r\n",
    "    time_index = np.arange(8761, dtype=int)\r\n",
    "\r\n",
    "    generation_index = {}\r\n",
    "\r\n",
    "    for abbr, df in generation_dic.items():\r\n",
    "        generation_index[abbr] = [x for x in df.columns.values]\r\n",
    "\r\n",
    "    generation_fuels = np.array(list(set([item for sublist in generation_index.values() for item in sublist])))\r\n",
    "    generation_fuels.sort()\r\n",
    "\r\n",
    "    imports_index = {}\r\n",
    "    exports_index = {}\r\n",
    "\r\n",
    "    for abbr in abbr_list:\r\n",
    "        imports_index[abbr] = [x for x in transmission_data.columns.values if abbr in x[-2:]]\r\n",
    "        exports_index[abbr] = [x for x in transmission_data.columns.values if abbr in x[:2]]\r\n",
    "\r\n",
    "    transmission_index = np.array(transmission_data.columns.values)\r\n",
    "    transmission_index.sort()\r\n",
    "\r\n",
    "    # In the following commands, we initiate the pyomo optimization with 'Gurobi' solver\r\n",
    "    # We declare the three variables 'delta_generation', 'delta_load' and 'delta_transmission'\r\n",
    "    # 'delta_generation' consists of 4,730,940 values which vary with country, generation_source and timestep.\r\n",
    "    # 'delta_load' consists of 236,547 values which vary with country and timestep.\r\n",
    "    # 'delta_transmission' consists of 543,182 values which vary with timestep and with country indirectly.\r\n",
    "    # We declare the model constraint as the sum of (delta_generation + generation + delta_transmission(imports) + imports) is equal to the sum of (delta_load + load + delta_transmission(exports) + exports) in all time steps.\r\n",
    "    # We declare objective function as to MINIMIZE the sum of (delta_generation^2 * sigma(generaion)) + sum of (delta_load^2 * sigma(load)) + sum of (delta_transmission^2 * sigma(transmission)) in all timesteps.\r\n",
    "    # Then solve the model.\r\n",
    "\r\n",
    "    model = pyo.ConcreteModel()\r\n",
    "\r\n",
    "    model.country_index = pyo.Set(initialize=country_index)\r\n",
    "    model.time_index = pyo.Set(initialize=time_index)\r\n",
    "    model.generation_fuels = pyo.Set(initialize=generation_fuels)\r\n",
    "    model.transmission_index = pyo.Set(initialize=transmission_index)\r\n",
    "\r\n",
    "    model.delta_generation = pyo.Var(model.country_index, model.time_index, model.generation_fuels, bounds=(0.0, None))\r\n",
    "    model.delta_load = pyo.Var(model.country_index, model.time_index, bounds=(0.0, None))\r\n",
    "    model.delta_transmission = pyo.Var(model.time_index, model.transmission_index, bounds=(0.0, None))\r\n",
    "\r\n",
    "    print('VARIABLES DECLARED')\r\n",
    "\r\n",
    "    def balance_rule(model, country, time):\r\n",
    "        return sum(model.delta_generation[country, time, generation] + generation_dic[country][generation][time] for generation in generation_index[country]) + sum(model.delta_transmission[time, link] + transmission_data[link][time] for link in imports_index[country]) ==  \\\r\n",
    "            model.delta_load[country, time] + load_dic[country][\"demand\"][time] + \\\r\n",
    "            sum(model.delta_transmission[time, link] + transmission_data[link][time] for link in exports_index[country])\r\n",
    "    model.balance_rule = pyo.Constraint(model.country_index, model.time_index, rule=balance_rule)\r\n",
    "\r\n",
    "    def ObjRule(model):\r\n",
    "        return sum(model.delta_generation[country, time, generation] ** 2 * float(sigma[country][generation].iloc[time]) for country in model.country_index for time in model.time_index for generation in generation_index[country]) \\\r\n",
    "            + sum(model.delta_transmission[time, link] ** 2 * float(sigma[\"transmission_data\"][link].iloc[time]) for time in model.time_index for link in model.transmission_index)\\\r\n",
    "            + sum(model.delta_load[country, time] ** 2 * float(sigma[country][\"demand\"].iloc[time]) for country in model.country_index for time in model.time_index)\r\n",
    "\r\n",
    "    model.obj = pyo.Objective(rule=ObjRule, sense=pyo.minimize)\r\n",
    "    opt = SolverFactory(\"gurobi\", solver_io=\"python\")\r\n",
    "    opt.solve(model)\r\n",
    "    print('OPTIMIZATION COMPLETED')\r\n",
    "\r\n",
    "    # In the following commands we copy the pyomo results into different intermediary variables.\r\n",
    "    # We create 'intermediary_var' dictionary and inside it create two other dictionaries as keys called 'generation' and 'load' and create a dataframe as another key called 'transmission'.\r\n",
    "    # We create 'unit_var' dictionary and inside it create two other dictionaries as keys called 'generation' and 'load' and create a dataframe as another key called 'transmission'.\r\n",
    "    # We fill the 'intermediary_var[\"generation\"]' from the 'delta_generation' values and 'intermediary_var[\"load\"]' with 'delta_load' values and 'intermediary_var[\"transmission\"]' from 'delta_transmission' values.\r\n",
    "    # We fill 'unit_var[\"generation\"]', 'unit_var[\"load\"]' and 'unit_var[\"transmission\"]' which have the same size as of 'intermediary_var[\"generation\"]', 'intermediary_var[\"load\"]' and ''intermediary_var[\"transmission\"]' with integer 1.\r\n",
    "\r\n",
    "    \r\n",
    "    generation_index_copy = copy.deepcopy(generation_index)\r\n",
    "\r\n",
    "    intermediary_var = {}\r\n",
    "    intermediary_var[\"generation\"] = {}\r\n",
    "    intermediary_var[\"load\"] = {}\r\n",
    "    unit_var = {}\r\n",
    "    unit_var[\"generation\"] = {}\r\n",
    "    unit_var[\"load\"] = {}\r\n",
    "\r\n",
    "    for country in country_index:\r\n",
    "        table_gen = []\r\n",
    "        row_load = []\r\n",
    "        for time in time_index:\r\n",
    "            row_gen = []\r\n",
    "            for generation in generation_index_copy[country]:\r\n",
    "                row_gen.append(model.delta_generation[country, time, generation].value)\r\n",
    "            table_gen.append(row_gen)\r\n",
    "            row_load.append(model.delta_load[country, time].value)\r\n",
    "\r\n",
    "        intermediary_var[\"generation\"][country] = pd.DataFrame.from_records(table_gen)\r\n",
    "        intermediary_var[\"load\"][country] = pd.DataFrame(row_load)\r\n",
    "        intermediary_var[\"generation\"][country].columns = generation_index_copy[country]\r\n",
    "        intermediary_var[\"load\"][country].columns = ['demand']\r\n",
    "        intermediary_var[\"generation\"][country].to_csv(\"../Data Sources/output/Internal Sigma/Debugging/\" + \"internal_sigma_gen_\" + country + \".csv\")\r\n",
    "        intermediary_var[\"load\"][country].to_csv(\"../Data Sources/output/Internal Sigma/Debugging/\" + \"internal_sigma_load_\" + country + \".csv\")\r\n",
    "        unit_var[\"generation\"][country] = pd.DataFrame(1, index=np.arange(df.shape[0]), columns=generation_index_copy[country])\r\n",
    "        unit_var[\"load\"][country] = pd.DataFrame(1, index=np.arange(df.shape[0]), columns=['demand'])\r\n",
    "\r\n",
    "    table_transmission = []\r\n",
    "\r\n",
    "    for time in time_index:\r\n",
    "        row = []\r\n",
    "        for link in transmission_index:\r\n",
    "            row.append(model.delta_transmission[time, link].value)\r\n",
    "        table_transmission.append(row)\r\n",
    "    intermediary_var[\"transmission\"] = pd.DataFrame.from_records(table_transmission)\r\n",
    "    intermediary_var[\"transmission\"].columns = transmission_index\r\n",
    "    intermediary_var[\"transmission\"].to_csv(\"../Data Sources/output/Internal Sigma/Debugging/internal_sigma_transmission.csv\")\r\n",
    "    unit_var[\"transmission\"] = pd.DataFrame(1, index=np.arange(transmission_data.shape[0]), columns=transmission_data.columns)\r\n",
    "\r\n",
    "    generation_dic_copy = copy.deepcopy(generation_dic)\r\n",
    "    transmission_data_copy = copy.deepcopy(transmission_data)\r\n",
    "\r\n",
    "    # We send the intermediary_var and unit_var to 'data_preperation.ipynb' to get the consolidated generation,load and transmission values.\r\n",
    "\r\n",
    "    consolidated_gen_data, consolidated_load_data, consolidated_transmission_data = dp.data_consolidation(generation_dic_copy, load_dic, transmission_data_copy, intermediary_var, unit_var)\r\n",
    "\r\n",
    "    return(consolidated_gen_data, consolidated_load_data, consolidated_transmission_data)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SIGMA CALCULATED\n",
      "VARIABLES DECLARED\n",
      "Academic license - for non-commercial use only - expires 2021-07-30\n",
      "Using license file C:\\Users\\lovin\\gurobi.lic\n",
      "DONE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# generation_index_copy = copy.deepcopy(generation_index)\r\n",
    "\r\n",
    "# intermediary_var = {}\r\n",
    "# intermediary_var[\"generation\"] = {}\r\n",
    "# intermediary_var[\"load\"] = {}\r\n",
    "# unit_var = {}\r\n",
    "# unit_var[\"generation\"] = {}\r\n",
    "# unit_var[\"load\"] = {}\r\n",
    "\r\n",
    "# for country in country_index:\r\n",
    "#     table_gen = []\r\n",
    "#     row_load = []\r\n",
    "#     for time in time_index:\r\n",
    "#         row_gen = []\r\n",
    "#         for generation in generation_index_copy[country]:\r\n",
    "#             row_gen.append(model.delta_generation[country, time, generation].value)\r\n",
    "#         table_gen.append(row_gen)\r\n",
    "#         row_load.append(model.delta_load[country, time].value)\r\n",
    "\r\n",
    "#     intermediary_var[\"generation\"][country] = pd.DataFrame.from_records(table_gen)\r\n",
    "#     intermediary_var[\"load\"][country] = pd.DataFrame(row_load)\r\n",
    "#     intermediary_var[\"generation\"][country].columns = generation_index_copy[n]\r\n",
    "#     intermediary_var[\"load\"][country].columns = ['demand']\r\n",
    "#     intermediary_var[\"generation\"][country].to_csv(\"../Data Sources/output/Internal Sigma/Debugging/\" + \"internal_sigma_gen_\" + country + \".csv\")\r\n",
    "#     intermediary_var[\"load\"][country].to_csv(\"../Data Sources/output/Internal Sigma/Debugging/\" + \"internal_sigma_load_\" + country + \".csv\")\r\n",
    "#     unit_var[\"generation\"][country] = pd.DataFrame(1, index=np.arange(df.shape[0]), columns=generation_index_copy[country])\r\n",
    "#     unit_var[\"load\"][country] = pd.DataFrame(1, index=np.arange(df.shape[0]), columns=['demand'])\r\n",
    "\r\n",
    "# table_transmission = []\r\n",
    "\r\n",
    "# for time in time_index:\r\n",
    "#     row = []\r\n",
    "#     for link in transmission_index:\r\n",
    "#         row.append(model.delta_transmission[time, link].value)\r\n",
    "#     table_transmission.append(row)\r\n",
    "# intermediary_var[\"transmission\"] = pd.DataFrame.from_records(table_transmission)\r\n",
    "# intermediary_var[\"transmission\"].columns = transmission_index\r\n",
    "# intermediary_var[\"transmission\"].to_csv(\"../Data Sources/output/Internal Sigma/Debugging/internal_sigma_transmission.csv\")\r\n",
    "# unit_var[\"transmission\"] = pd.DataFrame(1, index=np.arange(transmission_data.shape[0]), columns=transmission_data.columns) \r\n",
    "\r\n",
    "# generation_dic_copy = copy.deepcopy(generation_dic)\r\n",
    "# transmission_data_copy = copy.deepcopy(transmission_data)\r\n",
    "# consolidated_gen_data, consolidated_load_data, consolidated_transmission_data = dp.data_consolidation(generation_dic.copy,load_dic,transmission_data_copy)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# load_dic = dp.load(countries)[1]\r\n",
    "# generation_dic = dp.generation(countries)[1]\r\n",
    "# transmission_data = dp.cross_border(list(countries.values()))[1]\r\n",
    "# load_gen_dic = {}\r\n",
    "# for abbr, df in generation_dic.items():\r\n",
    "#     generation_index[abbr] = [x for x in df.columns.values]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# internal_sigma(dp.load(countries)[1], dp.generation(countries)[1], dp.cross_border(abbr_list)[1],countries)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Mismatch analysis in the consolidated ENTSO-E data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def mismatch_consolidated_data(consolidated_gen_data, consolidated_load_data, consolidated_transmission_data, countries):\r\n",
    "\r\n",
    "    # In the above consolidated ENTSO-E data, we carry out a mismatch analysis using anuual (generation + imports - load - exports) in each country.\r\n",
    "    \r\n",
    "    temp_dic = {}\r\n",
    "\r\n",
    "    temp_transmission = pd.read_csv('../Data Sources/output/Internal Sigma/Reconciled data/Transmission/all_transmissions.csv')\r\n",
    "\r\n",
    "    for country,abbr in countries.items():\r\n",
    "        temp_gen = pd.read_csv(f'../Data Sources/output/Internal Sigma/Reconciled data/Generation/{abbr}.csv').iloc[:, 1:]\r\n",
    "        temp_load = pd.read_csv(f'../Data Sources/output/Internal Sigma/Reconciled data/Load/{abbr}.csv').iloc[:, 1:]\r\n",
    "\r\n",
    "        temp_dic.update({country: [temp_gen.sum(axis=1).sum(), temp_transmission.filter(like=f'> {abbr}').sum(axis=1).sum(), temp_load.sum(), temp_transmission.filter(like=f'{abbr} -').sum(\r\n",
    "            axis=1).sum()]})\r\n",
    "\r\n",
    "    mismatch_data = pd.DataFrame(columns=['Country', 'Generation [GWh]', 'Imports [GWh]', 'Demand [GWh]', 'Exports [GWh]', 'Mismatch [GWh]'])\r\n",
    "    mismatch_data.iloc[:, 0] = temp_dic.keys()\r\n",
    "\r\n",
    "    for i in range(4):\r\n",
    "        mismatch_data.iloc[:,i+1] = [round(x[i]/1000,2) for x in temp_dic.values()]\r\n",
    "    mismatch_data.iloc[:,5] = abs(mismatch_data.iloc[:,1] + mismatch_data.iloc[:,2] - mismatch_data.iloc[:,3] - mismatch_data.iloc[:,4])\r\n",
    "\r\n",
    "    display(mismatch_data)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}