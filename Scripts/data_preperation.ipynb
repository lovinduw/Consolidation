{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries={ 'Austria': 'AT', 'Belgium': 'BE',  'Bulgaria': 'BG', 'Switzerland': 'CH', 'Czech Republic': 'CZ', 'Germany': 'DE', 'Denmark': 'DK', 'Estonia': 'EE', 'Spain': 'ES', 'Finland': 'FI', 'France': 'FR',  'Greece': 'GR', 'Hungary': 'HU', 'Ireland': 'IE', 'Italy': 'IT', 'Lithuania': 'LT', 'Latvia': 'LV', 'Montenegro': 'ME','Netherlands': 'NL', 'Norway': 'NO', 'Poland': 'PL', 'Portugal': 'PT', 'Serbia': 'RS', 'Sweden': 'SE', 'Slovenia': 'SI', 'Slovakia': 'SK', 'United Kingdom': 'UK'}\n",
    "\n",
    "abbr_list=list(countries.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the first,second,third and fourth columns of the dataframe as date,month,year and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "temp=pd.read_csv('../Data Sources/ENTSO-E/2018/Load/Croatia.csv')\n",
    "data['Day']=temp['Time (CET)'].str[:2]\n",
    "data['Month']=temp['Time (CET)'].str[3:5]\n",
    "data['Year']=temp['Time (CET)'].str[6:10]\n",
    "data['Time']=temp['Time (CET)'].str[11:16]+' - '+temp['Time (CET)'].str[29:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the country speciic Load data set, Austria,Belgium,Germany,Hungary,Netherlands report data every 15 minutes. \r\n",
    "# Therefore, these countries have 35044 data points per year. \r\n",
    "# UK and Ireland report data every 30 minutes henece these countries have 17522 datapoints per year. \r\n",
    "# All the others report every 1 hour hence have 8761 datapoints per year. \r\n",
    "# In Genearion dataset, situation is same as abobe except Belgium reports hourly data hence have 8761 datapoints. \r\n",
    "# In Transmission dataset, all countries report data hourly except Germany which reports every 15 minutes. \r\n",
    "# Therefroe,it is easy if all the data are converted to hourly data. \r\n",
    "# To do that in the countries with 35044 datapoints, mean is calculated in every successive 4 datapoints. \r\n",
    "# In the countries with 17522 datapoints, mean is calculated in every successive 2 datapoints.`\r\n",
    "\r\n",
    "def hourly_data(df):\r\n",
    "    length=len(df.index)\r\n",
    "    if length==35044:\r\n",
    "        divider=4\r\n",
    "    elif length==17522:\r\n",
    "        divider=2\r\n",
    "    else:\r\n",
    "        divider=1\r\n",
    "\r\n",
    "    # Following command creates a numpy array with a length similar to the length of the dataframe. \r\n",
    "    # Values of the array are obtained by getting the floor division of the length value. \r\n",
    "    # For example, when divider=4, this array will be [0,0,0,0,1,1,1,1,2,2,2,2,....]. \r\n",
    "    # Then the rows of the dataframe will be grouped according to the order of the numpy array with the mean value of those 4 rows. \r\n",
    "    # For example, in the numpy array first 4 values are similar. Accordingly first 4 rows of the dataframe will be grouped and get the mean value of those rows \r\n",
    "    \r\n",
    "    df=df.groupby(np.arange(length)//divider).mean()\r\n",
    "    return(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(countries):\n",
    "\n",
    "    load_data=pd.DataFrame()\n",
    "    load_data[['Day','Month','Year','Time']]=data[['Day','Month','Year','Time']]\n",
    "\n",
    "    # In the following command we open the csv file of each country and save the data in the 'temp' dataframe. \n",
    "    # Then we call the 'hourly_data' function to make all the time steps to hourly data. \n",
    "    # Then the column 'Actual Total Load [MW] - {country_name} ({country_code})' is saved in the new dataframe 'load_data' under the column name '{country_code}'. \n",
    "    # For example, the column 'Actual Total Load [MW] - Germany (DE)' in the 'temp' dataframe will be saved in the 'load_data' dataframe under the column name 'DE'.\n",
    "    \n",
    "    for country,abbr in countries.items():\n",
    "        temp=pd.read_csv(f'../Data Sources/ENTSO-E/2018/Load/{country}.csv')\n",
    "        temp=hourly_data(temp)\n",
    "        load_data[f'{abbr}']=temp[f'Actual Total Load [MW] - {country} ({abbr})']\n",
    "        \n",
    "    return(load_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing Generation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(countries):\n",
    "    \n",
    "    generation_data=pd.DataFrame()\n",
    "    generation_data[['Day','Month','Year','Time']]=data[['Day','Month','Year','Time']]\n",
    "\n",
    "    # In the following command we open the csv file of each country and save the data in the 'temp' dataframe. \n",
    "    # Then we call the 'hourly_data' function to make all the time steps to hourly data. \n",
    "    # Then we get the column names of the 'temp' dataframe into a numpy array called 'fuels'. \n",
    "    # Then we get the column name without the '- Actual Aggregated [MW]' part into a new variable called 'edited_fuel'. \n",
    "    # Then the column 'fuel' is saved in the new dataframe 'load_data' under the column name '{country_code} - {edited_fuel}'. For example, the column 'Biomass  - Actual Aggregated [MW]' of Germany in the 'temp' dataframe will be saved in the 'load_data' dataframe under the column name 'DE - Biomass'. \n",
    "    # Then we filter the column heads which have the string '{country_code}' in the column name and get the sum of each row in those columns and save it in a new column called '{country_code} - Total'. \n",
    "    # For example, 'DE - Total', 'UK - Total' \n",
    "        \n",
    "    for country,abbr in countries.items():\n",
    "        temp=pd.read_csv(f'../Data Sources/ENTSO-E/2018/Generation/{country}.csv',low_memory=False)\n",
    "        temp=hourly_data(temp)\n",
    "\n",
    "        fuels=np.array(temp.columns)\n",
    "        for fuel in fuels:\n",
    "            edited_fuel=fuel[:-26]\n",
    "            generation_data[f'{abbr} - {edited_fuel}']=temp[fuel]\n",
    "        generation_data[f'{abbr} - Total'] = generation_data.filter(like=abbr).sum(axis=1)\n",
    "\n",
    "    return(generation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparing Cross-border Transmission Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_border(abbr_list):\n",
    "\n",
    "    transmission_data = pd.DataFrame()\n",
    "    transmission_data = data[['Day','Month','Year','Time']]\n",
    "    cross_border_data = pd.DataFrame()\n",
    "    cross_border_data[['Day','Month','Year','Time']]=data[['Day','Month','Year','Time']]\n",
    "\n",
    "# In the following command we get the list of the paths of all files in the directory. \n",
    "# Then one by one the csv associated with the path is copied to the dataframe 'temp' only if the file path string includes the country_code sent by 'abbr_list'. \n",
    "# For this we check the characters from 37 to 39 in the file path. \n",
    "# Then we make all the 'n/e' values of the 'temp' 0. \n",
    "# Then we cretae two new column in the 'transmission_data_temp' dataframe and name it as the two country codes the power transmission occurs. \n",
    "# We use string editing to get the two country codes from the file path. \n",
    "# For example, in the power transmission occur between Germany and Austria, we name the column as 'DE --> AT' and if the power transmission occur between Austria and Germany, we name the column as 'DE <-- AT'.\n",
    "# We use 'pd.to_numeric' function to convert the string values to numerical values if any numeric values have been recorded as string in the datasets. \n",
    "# Then we send the numeric converted column to 'hourly_data' function because cross border trasnmissions occur between Germany and a some countries have 35044 data points but We need to convert them to hourly values.\n",
    "# In the 'transmission_data_temp' dataframe, columns with '<' sign shows the inbound transmission to the country and columns with '>' sign shows the outbound transmission from the country. \n",
    "# After this step we assume inbound power transmission as a negative value and outbound transmission as a positive value. \n",
    "# Inbound and outbound both do not occur at the same time in a given time step. \n",
    "# Therefore we multiply the '<' columns of the 'transmission_data_temp' dataframe by -1 and add the '>' columns of the 'transmission_data_temp' to get the net inbound/outbound in that country in that particular time step and save that in the above mentioned column of the 'cross_border_data' dataframe. \n",
    "# After all the csvs from a single country are read, we join the 'transmission_data_temp' dataframe to 'transmission_data' dataframe.\n",
    "\n",
    "    csvs = glob.glob(\"../Data Sources/ENTSO-E/2018/Transmission/*.csv\")\n",
    "\n",
    "    for abbr in abbr_list:\n",
    "        transmission_data_temp = pd.DataFrame()\n",
    "        for csv in csvs:\n",
    "            if csv[42:44] == abbr:\n",
    "                temp = pd.read_csv(csv)\n",
    "                temp = temp.replace(['n/e',np.nan] ,0)\n",
    "                \n",
    "                transmission_data_temp[f'{csv[42:44]} -- > {csv[45:47]}'] = hourly_data(pd.to_numeric(temp.iloc[:,2]))\n",
    "                transmission_data_temp[f'{csv[42:44]} < -- {csv[45:47]}'] = hourly_data(pd.to_numeric(temp.iloc[:,1]))  \n",
    "            \n",
    "        transmission_data = pd.concat([transmission_data,transmission_data_temp],axis=1)\n",
    "        cross_border_data[f'{abbr}'] = transmission_data_temp.filter(like='>').sum(axis=1) + (transmission_data_temp.filter(like='<').sum(axis=1))*-1\n",
    "        \n",
    "    \n",
    "    \n",
    "    return cross_border_data,transmission_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Calculating net imports/exports based on generation and load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_export_using_load_gen(load_data, generation_data, abbr_list):\n",
    "\n",
    "    import_export_data = pd.DataFrame()\n",
    "    import_export_data[['Day', 'Month', 'Year', 'Time']] = load_data[['Day', 'Month', 'Year', 'Time']]\n",
    "\n",
    "    # In the following command we calculate net import/export in each time step of each country by subtracting '{country_code}' column of 'load_data' dataframe from '{country_code} - Total' of 'generation_data' dataframe and save the result in '{country_code} - [gen - load]' column of 'import_export_data' dataframe.\n",
    "    # for example, import_export_data['DE - [gen - load]']=generation_data['DE - Total'] - load_data['DE'].\n",
    "    # Then we create a new column in the 'import_export_data' dataframe called '{country_code} - import/export' and make that column 'Net Export' if '{country_code} - [gen - load]' is greater than 0 and make the '{country_code} - import/export' column 'Net Import' if '{country_code} - [gen - load]' is equal or lower than 0\n",
    "\n",
    "    for abbr in abbr_list:\n",
    "        import_export_data[f'{abbr}'] = generation_data[f'{abbr} - Total'] - \\\n",
    "            load_data[f'{abbr}']\n",
    "#         import_export_data.loc[import_export_data[f'{abbr} - [gen - load]'] > 0, f'{abbr} - import/export'] = 'Net Export'\n",
    "#         import_export_data.loc[import_export_data[f'{abbr} - [gen - load]'] <= 0, f'{abbr} - import/export'] = 'Net Import'\n",
    "\n",
    "    return(import_export_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Calculating net imports/exports based on cross-border transmission data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_export_using_crossborder(crossborder_data, abbr_list):\n",
    "\n",
    "    import_export_data = pd.DataFrame()\n",
    "    import_export_data[['Day', 'Month', 'Year', 'Time']] = crossborder_data[['Day', 'Month', 'Year', 'Time']]\n",
    "\n",
    "# In the following command we copy the '{country_code}' column of 'crossborder_data' dataframe to '{country_code} - [exp - imp]' column of 'import_export_data' dataframe.\n",
    "# for example, import_export_data['DE - [exp - imp]'].\n",
    "# Then we create a new column in the 'import_export_data' dataframe called '{country_code} - import/export' and make that column 'Net Export' if '{country_code} - [exp - imp]' is greater than 0 and make the '{country_code} - import/export' column 'Net Import' if '{country_code} - [exp - imp]' is equal or lower than 0\n",
    "\n",
    "    for abbr in abbr_list:\n",
    "        import_export_data[f'{abbr}'] = crossborder_data[f'{abbr}']\n",
    "#         import_export_data.loc[import_export_data[f'{abbr} - [exp - imp]'] > 0, f'{abbr} - import/export'] = 'Net Export'\n",
    "#         import_export_data.loc[import_export_data[f'{abbr} - [exp - imp]'] <= 0, f'{abbr} - import/export'] = 'Net Import'\n",
    "\n",
    "    return(import_export_data)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}