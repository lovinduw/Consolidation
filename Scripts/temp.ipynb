{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import import_ipynb\r\n",
    "import glob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "countries={ 'Austria': 'AT', 'Belgium': 'BE',  'Bulgaria': 'BG', 'Switzerland': 'CH', 'Czech Republic': 'CZ',  'Germany': 'DE', 'Denmark': 'DK', 'Estonia': 'EE', 'Spain': 'ES', 'Finland': 'FI', 'France': 'FR',  'Greece': 'GR', 'Hungary': 'HU', 'Ireland': 'IE', 'Italy': 'IT', 'Lithuania': 'LT', 'Latvia': 'LV', 'Montenegro': 'ME','Netherlands': 'NL', 'Norway': 'NO', 'Poland': 'PL', 'Portugal': 'PT', 'Serbia': 'RS', 'Sweden': 'SE', 'Slovenia': 'SI', 'Slovakia': 'SK', 'United Kingdom': 'UK'}\r\n",
    "\r\n",
    "abbr_list=list(countries.values())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "fuels=['Biomass', 'Fossil Brown coal/Lignite', 'Fossil Coal-derived gas', 'Fossil Gas', 'Fossil Hard coal', 'Fossil Oil', 'Fossil Oil shale', 'Fossil Peat', 'Geothermal', 'Hydro Pumped Storage', 'Hydro Pumped Storage', 'Hydro Run-of-river and poundage', 'Hydro Water Reservoir', 'Marine', 'Nuclear', 'Other', 'Other renewable', 'Solar', 'Waste', 'Wind Offshore', 'Wind Onshore']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import matplotlib.pyplot as plt \r\n",
    "\r\n",
    "# from sklearn.linear_model import LinearRegression\r\n",
    "# from sklearn.preprocessing import PolynomialFeatures\r\n",
    "# from sklearn.metrics import mean_squared_error\r\n",
    "# from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import data_preperation as dp"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from data_preperation.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "load_dic = dp.load(countries)[1]\r\n",
    "gen_dic = dp.generation(countries)[1]\r\n",
    "transmission_data = dp.cross_border(abbr_list)[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def sigma(load_data, generation_data, transmission_data, abbr_list):\r\n",
    "\r\n",
    "    eph = 0.1\r\n",
    "    A = 100\r\n",
    "    load_gen_data = {}\r\n",
    "    sigma = {}\r\n",
    "\r\n",
    "    # First we create a new dictionary called 'load_gen_data' and in that dictionary keys are country_abbreviations and as value of each key we add the combined demand column of each country and generation columns from all the sources in that country.\r\n",
    "    # Then in each value of the dictionary (which is a dataframe), we add new columns with the name '{Original_column_name} moving_average' and make it 0.\r\n",
    "    # Then we get the moving average of each timestep using the values in that same time period in the last 10 days.\r\n",
    "    # This creates null values in the first 10 days of the year. We fill them with the values from the original column.\r\n",
    "    # Then in these 'moving_average' columns we replace the value with 0.1, if the current value is less than 0.1.\r\n",
    "    # Then in these 'moving_average' columns we change the value as 100/current_value.\r\n",
    "    # Then we filter only the column names which have 'moving_avareg' as column name and remove the 'moving_average' part from the column name.\r\n",
    "    # We save the resultant dataframe as a value in a dictionary called 'sigma' with the key as country_abbreviation.\r\n",
    "    # We do the same procedure for transmission_data and save the resultant dataframe as the value of 'transmission_data' key of 'sigma' dictionary.\r\n",
    "\r\n",
    "    for abbr, df in generation_data.items():\r\n",
    "        load_gen_data[abbr] = pd.concat([df, load_data[abbr]], axis=1)\r\n",
    "\r\n",
    "    for abbr, df in load_gen_data.items():\r\n",
    "        for column in df.columns.values:\r\n",
    "            column_data = [[index, value]\r\n",
    "                           for index, value in enumerate(df.loc[:, column])]\r\n",
    "            for index, value in column_data:\r\n",
    "                if pd.isnull(value):\r\n",
    "                    temp_list = [[abs(index-item[0]), item[1]]\r\n",
    "                                 for item in column_data if (index-item[0]) % 24 == 0]\r\n",
    "                    temp_list.sort()\r\n",
    "                    moving_average = [x[1] for x in temp_list[1:11]]\r\n",
    "                    moving_average = [0 if pd.isna(\r\n",
    "                        x) else x for x in moving_average]\r\n",
    "                    df.loc[index, column] = np.mean(np.array(moving_average))\r\n",
    "            df[column] = df[column].apply(lambda x: eph if x < eph else x)\r\n",
    "            df[column] = df[column].apply(lambda x:  A/x)\r\n",
    "        sigma[abbr] = df\r\n",
    "\r\n",
    "    for column in transmission_data.columns.values:\r\n",
    "        column_data = [[index, value] for index,\r\n",
    "                       value in enumerate(transmission_data.loc[:, column])]\r\n",
    "        for index, value in column_data:\r\n",
    "            if pd.isnull(value):\r\n",
    "                temp_list = [[abs(index-item[0]), item[1]]\r\n",
    "                             for item in column_data if (index-item[0]) % 24 == 0]\r\n",
    "                temp_list.sort()\r\n",
    "                moving_average = [x[1] for x in temp_list[1:11]]\r\n",
    "                moving_average = [0 if pd.isna(\r\n",
    "                    x) else x for x in moving_average]\r\n",
    "                transmission_data.loc[index, column] = np.mean(\r\n",
    "                    np.array(moving_average))\r\n",
    "        transmission_data[column] = transmission_data[column].apply(\r\n",
    "            lambda x: eph if x < eph else x)\r\n",
    "        transmission_data[column] = transmission_data[column].apply(\r\n",
    "            lambda x:  A/x)\r\n",
    "    sigma[\"transmission_data\"] = transmission_data\r\n",
    "\r\n",
    "    return(sigma)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "sigma = sigma(load_dic,gen_dic,transmission_data,abbr_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for key,value in sigma.items():\r\n",
    "    print(key)\r\n",
    "    for column in value.columns.values:\r\n",
    "        print(column,value[column].isnull().sum())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AT\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "BE\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "BG\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "CH\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "CZ\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "DE\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "DK\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "EE\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "ES\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "FI\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "FR\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "GR\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "HU\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "IE\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "IT\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "LT\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "LV\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "ME\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "NL\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "NO\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "PL\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "PT\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "RS\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "SE\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "SI\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "SK\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "UK\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "transmission_data\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acb9e0cfff3151089362f20c3a81c7531326aa2c5fdbbc2eccac94359104a8e2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('Python39')"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}